---
title: "The Curse of Dimensionality"
shortDescription: "A short data-visualization film about predictive models of risk, show at the 2025 Venice Architecture Biennale."
date: 2025-04-15
team: ["Adeline Chum", "Michael Krisch", "Laura Kurgan", "Adam Vosburgh", "Jia Zhang"]
tags: ["main", "projects"]
images:
  - "/images/curse-of-dim/installation-pic.jpg"
  - "/images/curse-of-dim/still-danger.jpg"
  - "/images/curse-of-dim/installation-grid.jpg"
  - "/images/curse-of-dim/still-fb-intro.jpg"
display:
  coverImage: "/images/curse-of-dim/installation-pic.jpg"      
  slideshowImages:                               
    - "/images/curse-of-dim/installation-pic.jpg"
  showInSlideshow: true    
layout: "item.njk"
size: 3
link: https://c4sr.columbia.edu/projects/curse-dimensionality
---

The Curse of Dimensionality explores predictive models of risk — computational models, built from Artificial Intelligence and machine learning methods —  that assess different kinds of threats present in both physical and virtual spaces. These predictive tools are deployed by governments, corporations, and civil society, and, in the name of safety and security, strike an unstable balance between protection and harm. The Curse of Dimensionality spotlights the ways that algorithmic systems, reliant on vast troves of data, translate people and places into the language of risk, an abstraction that can inadvertently justify conflict and exacerbate existing disparities. Through simulations, the project draws attention to these overlooked junctures of power. The aim is to train the senses of the audience to see, hear, and confront the hidden complexities at the heart of this threat analysis — explaining those subtle, often invisible factors that increasingly shape conflict around the world.

Building on the team’s previous research into the urban history of the algorithms that create and polarize online communities, The Curse of Dimensionality investigates how computational intelligence systems define threats, measure risk, and track conflict. By characterizing patterns of violence into categories, accelerating decision-making, and shaping public perception, these models influence not only how conflicts are understood but also how they unfold. Are there systematic biases and how do they affect the people and places they are describing? When does uncertainty even become the logic of the system itself? Error is inevitable in any “intelligent system,” natural or artificial, especially those that seek to predict (and intervene in) the future based on past patterns. But it can be hard to see, let alone understand. This installation will expose the architecture of computational predictions of risks, as they play out in streets and cities around us today.

In technical terms, the “curse of dimensionality” names a problem of scaling — as the number of features (dimensions) in training data increases, models require exponentially more data to be accurate, and interpretability is often sacrificed. These ideas are unpacked across three related algorithms visualized in an animation.

